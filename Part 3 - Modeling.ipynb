{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Modeling\n",
    "\n",
    "In this notebook we will be focusing on our full modeling process. I will be doing some preprocessing, hyperperameter tuning, and fiting our data into a variety of models in order to determine which model seems to perform best. \n",
    "\n",
    "\n",
    "**Model Results**\n",
    "\n",
    "|Model|AUC Score|\n",
    "|---|---|\n",
    "|Baseline - Logistic Regression using TFIDF data| 0.58|\n",
    "|Logistic Regression using Count Vectorizer Data| 0.55|\n",
    "|KNN| 0.69|\n",
    "|SVC| 0.5|\n",
    "|Random Forest| 0.52|\n",
    "|**Neural Network - MLPClassifer**|**0.738**|\n",
    "\n",
    "The best model was using our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the holy trinity of data science packages\n",
    "import pandas as pd \n",
    "pd.options.display.max_rows = 4000\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Other visualization packages\n",
    "import seaborn as sns\n",
    "\n",
    "#Importing NLP plugins\n",
    "from nltk.corpus import stopwords \n",
    "stop_words = stopwords.words('english')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Importing our Sklearn Plugins\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#importing our models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Model Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "We need to do some feature engineering. I would like to one hot encode my categorical data, as well as fit a TFIDF Vectorizer to my text data column. Might do a Count Vectorizer as well, and see if that changes anything to my model. In addition, I probably want to fit a PCA to reduce computational time. \n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "1. One Hot Encode Cateogrical Data\n",
    "2. Fit in a TFIDF Vectorizer\n",
    "3. Fit in a Count Vectorizer\n",
    "4. Determine if using a PCA would help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import our dataset\n",
    "df = pd.read_csv('data/cleaned_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Copy\n",
    "df_2 = df.copy()\n",
    "\n",
    "# One Hot Encoding using Pandas get dummies function\n",
    "columns_to_1_hot = ['employment_type','required_experience','required_education',\n",
    "                   'industry', 'function']\n",
    "\n",
    "for column in columns_to_1_hot:\n",
    "    encoded = pd.get_dummies(df_2[column])\n",
    "    df_2 = pd.concat([df_2, encoded], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity sake, I will also drop the *title* & *location* columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Full-time</th>\n",
       "      <th>Other</th>\n",
       "      <th>Part-time</th>\n",
       "      <th>Temporary</th>\n",
       "      <th>...</th>\n",
       "      <th>Public Relations</th>\n",
       "      <th>Purchasing</th>\n",
       "      <th>Quality Assurance</th>\n",
       "      <th>Research</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Science</th>\n",
       "      <th>Strategy/Planning</th>\n",
       "      <th>Supply Chain</th>\n",
       "      <th>Training</th>\n",
       "      <th>Writing/Editing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  telecommuting  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...              0   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...              0   \n",
       "2  Our client, located in Houston, is actively se...              0   \n",
       "\n",
       "   has_company_logo  has_questions  fraudulent  Contract  Full-time  Other  \\\n",
       "0                 1              0           0         0          0      1   \n",
       "1                 1              0           0         0          1      0   \n",
       "2                 1              0           0         0          1      0   \n",
       "\n",
       "   Part-time  Temporary  ...  Public Relations  Purchasing  Quality Assurance  \\\n",
       "0          0          0  ...                 0           0                  0   \n",
       "1          0          0  ...                 0           0                  0   \n",
       "2          0          0  ...                 0           0                  0   \n",
       "\n",
       "   Research  Sales  Science  Strategy/Planning  Supply Chain  Training  \\\n",
       "0         0      0        0                  0             0         0   \n",
       "1         0      0        0                  0             0         0   \n",
       "2         0      1        0                  0             0         0   \n",
       "\n",
       "   Writing/Editing  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "\n",
       "[3 rows x 198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_1_hot += ['title', 'location']\n",
    "    \n",
    "#droping the original columns that we just one hot encoded from\n",
    "df_2 = df_2.drop(columns_to_1_hot, axis = 1)\n",
    "df_2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the description column \n",
    "\n",
    "First of all we need custom tokenizer to clean up our text data a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \n",
    "    #All characters in this string will be converted to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Removing sentence punctuations\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        text = text.replace(punctuation_mark,'')\n",
    "    \n",
    "    #Creating our list of tokens\n",
    "    list_of_tokens = text.split(' ')\n",
    "    #Creating our cleaned tokens list \n",
    "    cleaned_tokens = []\n",
    "    #Intatiating our Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    #Removing Stop Words in our list of tokens and any tokens that happens to be empty strings\n",
    "    for token in list_of_tokens:\n",
    "        if (not token in stop_words) and (token != ''):\n",
    "            #lemmatizing our token\n",
    "            token_lemmatized = lemmatizer.lemmatize(token)\n",
    "            #appending our finalized cleaned token\n",
    "            cleaned_tokens.append(token_lemmatized)\n",
    "    \n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiating our tfidf vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer = tokenizer, min_df = 0.05, ngram_range=(1,3))\n",
    "#Fit_transform our description \n",
    "tfidf_features = tfidf.fit_transform(df_2['description']) #this will create a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to append this sparse matrix to the original pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_df = pd.DataFrame(tfidf_features.todense(), columns = tfidf.get_feature_names())\n",
    "\n",
    "df_tfidf = pd.concat([df_2, tfidf_vect_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Full-time</th>\n",
       "      <th>Other</th>\n",
       "      <th>Part-time</th>\n",
       "      <th>Temporary</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>written communication</th>\n",
       "      <th>written verbal</th>\n",
       "      <th>year</th>\n",
       "      <th>year experience</th>\n",
       "      <th>you’ll</th>\n",
       "      <th></th>\n",
       "      <th>–</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 689 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  telecommuting  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...            0.0   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...            0.0   \n",
       "2  Our client, located in Houston, is actively se...            0.0   \n",
       "\n",
       "   has_company_logo  has_questions  fraudulent  Contract  Full-time  Other  \\\n",
       "0               1.0            0.0         0.0       0.0        0.0    1.0   \n",
       "1               1.0            0.0         0.0       0.0        1.0    0.0   \n",
       "2               1.0            0.0         0.0       0.0        1.0    0.0   \n",
       "\n",
       "   Part-time  Temporary  ...  write  writing  written  written communication  \\\n",
       "0        0.0        0.0  ...    0.0      0.0      0.0                    0.0   \n",
       "1        0.0        0.0  ...    0.0      0.0      0.0                    0.0   \n",
       "2        0.0        0.0  ...    0.0      0.0      0.0                    0.0   \n",
       "\n",
       "   written verbal  year  year experience  you’ll         –  \n",
       "0             0.0   0.0              0.0     0.0  0.0  0.0  \n",
       "1             0.0   0.0              0.0     0.0  0.0  0.0  \n",
       "2             0.0   0.0              0.0     0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 689 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now appended our tfdif results to our dataframe and we will need to drop the description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = df_tfidf.drop(['description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = df_tfidf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a similar procedure with a Count Vectorizer, so we can compare the two vectorizers in performance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiating our CountVectorizer\n",
    "count_vect = CountVectorizer(tokenizer = tokenizer, min_df = 0.05, ngram_range=(1,3))\n",
    "#Fit_transform our description \n",
    "count_vect_features = count_vect.fit_transform(df_2['description']) #this will create a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_df = pd.DataFrame(count_vec_features.todense(), columns = count_vect.get_feature_names())\n",
    "\n",
    "df_count_vect = pd.concat([df_2, count_vect_df], axis = 1)\n",
    "df_count_vect = df_count_vect.drop(['description'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_vect = df_count_vect.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>fraudulent</th>\n",
       "      <th>Contract</th>\n",
       "      <th>Full-time</th>\n",
       "      <th>Other</th>\n",
       "      <th>Part-time</th>\n",
       "      <th>Temporary</th>\n",
       "      <th>Associate</th>\n",
       "      <th>...</th>\n",
       "      <th>write</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>written communication</th>\n",
       "      <th>written verbal</th>\n",
       "      <th>year</th>\n",
       "      <th>year experience</th>\n",
       "      <th>you’ll</th>\n",
       "      <th></th>\n",
       "      <th>–</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 688 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   telecommuting  has_company_logo  has_questions  fraudulent  Contract  \\\n",
       "0            0.0               1.0            0.0         0.0       0.0   \n",
       "1            0.0               1.0            0.0         0.0       0.0   \n",
       "2            0.0               1.0            0.0         0.0       0.0   \n",
       "\n",
       "   Full-time  Other  Part-time  Temporary  Associate  ...  write  writing  \\\n",
       "0        0.0    1.0        0.0        0.0        0.0  ...    0.0      0.0   \n",
       "1        1.0    0.0        0.0        0.0        0.0  ...    0.0      0.0   \n",
       "2        1.0    0.0        0.0        0.0        0.0  ...    0.0      0.0   \n",
       "\n",
       "   written  written communication  written verbal  year  year experience  \\\n",
       "0      0.0                    0.0             0.0   0.0              0.0   \n",
       "1      0.0                    0.0             0.0   0.0              0.0   \n",
       "2      0.0                    0.0             0.0   0.0              0.0   \n",
       "\n",
       "   you’ll         –  \n",
       "0     0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  \n",
       "\n",
       "[3 rows x 688 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count_vect.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we now have two different dataframes with two different vectorizers preprocessing our description data. I will hold out on the PCA to see if I need it. I will only do it if the modelimg takes too long. \n",
    "\n",
    "**I will conduct the following steps:**\n",
    "1. Logistic Regression w/ Tfidf\n",
    "2. Logistic Regression w/ Count Vectorizer\n",
    "3. I will evaluate both models and determine which is better, and for simplicity stake pick the superior vectorizer for the other models I would like to run.\n",
    "4. KNearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 - Logistic Regresion w/ Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_tfidf.fraudulent\n",
    "features = df_tfidf.drop(['fraudulent'], axis = 1)\n",
    "\n",
    "#Spliting our Data into train and holdout sets to test our models\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(features, target, test_size = 0.1,\n",
    "                                                    stratify = target, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "#I want to optimze the C-Value\n",
    "c_values = [.00001, .0001, .001, .1, 1, 10, 100, 1000, 10000]\n",
    "penalty_options = ['l1','l2']\n",
    "\n",
    "param_grid = dict(C = c_values, penalty = penalty_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(log_reg, param_grid= param_grid, cv = 10, scoring = 'roc_auc', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1e-05, 0.0001, 0.001, 0.1, 1, 10, 100, 1000,\n",
       "                               10000],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8520861054296776\n",
      "{'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred = grid.predict(X_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5801411682352026\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_hold, log_reg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1196\n",
      "         1.0       0.70      0.16      0.26        43\n",
      "\n",
      "    accuracy                           0.97      1239\n",
      "   macro avg       0.84      0.58      0.62      1239\n",
      "weighted avg       0.96      0.97      0.96      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_hold, log_reg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Logistic Regression optimized for the C values and the penalty, we tested it with our hold out set only returned a 0.58 AUC score. Which highlights that our model is severely overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 - Logistic Regresion w/ Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_2 = df_count_vect.fraudulent\n",
    "features_2 = df_count_vect.drop(['fraudulent'], axis = 1)\n",
    "\n",
    "#Spliting our Data into train and holdout sets to test our models\n",
    "X_train_2, X_hold_2, y_train_2, y_hold_2 = train_test_split(features_2, target_2, test_size = 0.1,\n",
    "                                                    stratify = target_2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intiatiating our previous logistic regression model, using the count vectorizer dataset\n",
    "grid_count_vect = GridSearchCV(log_reg, param_grid= param_grid, cv = 10, scoring = 'roc_auc', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7766003404164705\n",
      "{'C': 0.1, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewberry/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "grid_count_vect.fit(X_train_2, y_train_2)\n",
    "print(grid_count_vect.best_score_)\n",
    "print(grid_count_vect.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_pred_2 = grid_count_vect.predict(X_hold_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.557721474683052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1196\n",
      "         1.0       0.83      0.12      0.20        43\n",
      "\n",
      "    accuracy                           0.97      1239\n",
      "   macro avg       0.90      0.56      0.59      1239\n",
      "weighted avg       0.96      0.97      0.96      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_hold_2, log_reg_pred_2))\n",
    "print(classification_report(y_hold_2, log_reg_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Count Vectorizer did not really improve from my previous model, as such I will stick with the tfidf data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 - KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - KNearestNeighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30]}\n"
     ]
    }
   ],
   "source": [
    "k_range = list(np.arange(2,32,2))\n",
    "param_grid_knn = dict(n_neighbors=k_range)\n",
    "print(param_grid_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn = GridSearchCV(knn, param_grid_knn, cv=10, scoring='roc_auc',\n",
    "                        n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9681148223918136\n",
      "{'n_neighbors': 8}\n"
     ]
    }
   ],
   "source": [
    "grid_knn.fit(X_train, y_train)\n",
    "print(grid_knn.best_score_)\n",
    "print(grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, just from the training score. It already seems that our KNearestNeighbors model is much better. Now let's test it with our holdout data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6964202380026444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      1196\n",
      "         1.0       0.85      0.40      0.54        43\n",
      "\n",
      "    accuracy                           0.98      1239\n",
      "   macro avg       0.91      0.70      0.76      1239\n",
      "weighted avg       0.97      0.98      0.97      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting our holdout data\n",
    "knn_pred = grid_knn.predict(X_hold)\n",
    "#Printing out our evaluation metrics\n",
    "print(roc_auc_score(y_hold, knn_pred))\n",
    "print(classification_report(y_hold, knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressive, by testing our KNN model on the holdout data, it seems to have improved by aroun 11 percentage points from our best logistic regression model. The KNN here is much superior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 - Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intatiating our SVM model\n",
    "svc = SVC(kernel = 'rbf', gamma = 'auto' )\n",
    "\n",
    "# I wont use a gridsearch because SVMs usually take a long looong time. I will just use a simple SVC\n",
    "# and see how it plays out\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9656471432415463"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1196\n",
      "         1.0       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.97      1239\n",
      "   macro avg       0.48      0.50      0.49      1239\n",
      "weighted avg       0.93      0.97      0.95      1239\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewberry/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting our holdout data\n",
    "svc_pred = svc.predict(X_hold)\n",
    "#Printing out our evaluation metrics\n",
    "#Printing out our evaluation metrics\n",
    "print(roc_auc_score(y_hold, svc_pred))\n",
    "print(classification_report(y_hold, svc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiating our random forest\n",
    "\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200]}\n"
     ]
    }
   ],
   "source": [
    "#The parameters we want to tune with our random forest\n",
    "n_estimators_range = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "\n",
    "param_grid_rf = dict(n_estimators=n_estimators_range)\n",
    "print(param_grid_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=10, scoring='roc_auc',\n",
    "                        n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8067208847452003\n",
      "{'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "grid_rf.fit(X_train, y_train)\n",
    "print(grid_rf.best_score_)\n",
    "print(grid_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5232558139534884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      1196\n",
      "         1.0       1.00      0.05      0.09        43\n",
      "\n",
      "    accuracy                           0.97      1239\n",
      "   macro avg       0.98      0.52      0.54      1239\n",
      "weighted avg       0.97      0.97      0.95      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_pred = grid_rf.predict(X_hold)\n",
    "#Printing out our evaluation metrics\n",
    "print(roc_auc_score(y_hold, rf_pred))\n",
    "print(classification_report(y_hold, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite dissapointed with the latest two models. SVC didn't do well, nor did the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 6 - Neural Net MLPC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instatiatie our MLPClassifier\n",
    "mlp = MLPClassifier(solver='lbfgs', \n",
    "                    activation = 'relu',\n",
    "                   hidden_layer_sizes = (100,50,20), \n",
    "                    max_iter = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 50, 20), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='lbfgs',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7383332037022633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1196\n",
      "         1.0       0.60      0.49      0.54        43\n",
      "\n",
      "    accuracy                           0.97      1239\n",
      "   macro avg       0.79      0.74      0.76      1239\n",
      "weighted avg       0.97      0.97      0.97      1239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_pred = mlp.predict(X_hold)\n",
    "\n",
    "#Printing out our evaluation metrics\n",
    "print(roc_auc_score(y_hold, mlp_pred))\n",
    "print(classification_report(y_hold, mlp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally our MLP classifier does the BEST JOB with an AUC score of 0.738% which is 15 percentage points better than our best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
